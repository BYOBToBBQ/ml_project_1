{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project_helpers import *\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute sigmoid function\n",
    "def sigmoid(z):\n",
    "    #return 1 / (1+np.exp(-z))\n",
    "    #This approximation of the sigmoid function avoids exp overflow\n",
    "    return .5 * (1 + np.tanh(.5 * z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute loss function\n",
    "def loss_f_lr(h, y):\n",
    "    #epsilon is added to log computations in order to avoid log(0) instances\n",
    "    epsilon = 0.00001\n",
    "    return (-y*np.log(h+epsilon) - (1-y)*np.log(1-h+epsilon)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(y, tx, initial_w, max_iters, gamma, pandas=False):\n",
    "   \n",
    "    w = initial_w\n",
    "    h = 0\n",
    "    loss_prev = 1000000\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "    \n",
    "        #Compute x_t*w\n",
    "        z = np.dot(tx, w)\n",
    "        #Compute sigmoid of z\n",
    "        h = sigmoid(z)\n",
    "        \n",
    "        loss_curr = loss_f_lr(h, y)\n",
    "        \n",
    "        if abs(loss_prev - loss_curr) < 0.00001:\n",
    "            break\n",
    "            \n",
    "        loss_prev = loss_curr\n",
    "\n",
    "        #Compute stochastic gradient\n",
    "        n = np.random.randint(len(y))\n",
    "        stoch_gradient = (h[n]-y[n]) * tx[n]\n",
    "        \n",
    "        #Update w according to stochastic gradient\n",
    "        update = gamma*stoch_gradient\n",
    "        w = w - update\n",
    "    \n",
    "    loss = loss_f_lr(h, y)\n",
    "    \n",
    "    return (w, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_logistic_regression(y, tx, lambda_, initial_w, max_iters, gamma):\n",
    "    \n",
    "    w = initial_w\n",
    "    h = 0\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "    \n",
    "        z = np.dot(tx, w)\n",
    "        h = sigmoid(z)\n",
    "\n",
    "        #The only difference with the previous function is the regularization constraint factored\n",
    "        #in the gradient computation\n",
    "        gradient = np.dot(tx.T, h-y) + lambda_*w\n",
    "        w = w - gamma*gradient\n",
    "    \n",
    "    loss = loss_f_lr(h, y) + (lambda_/2)*np.dot(w.T,w)\n",
    "    \n",
    "    return (w, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba(X, w):\n",
    "    return sigmoid(np.dot(X, w))\n",
    "\n",
    "def predict(X, w, threshold=0.5):\n",
    "    return proba(X, w) >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AIC_forward(y, x_pd):\n",
    "    \n",
    "    x = np.array(x_pd)\n",
    "    \n",
    "    left = set(range(x_pd.shape[1]))\n",
    "    left.remove(x_pd.shape[1]-1)\n",
    "    \n",
    "    picked = [x_pd.shape[1]-1]\n",
    "    \n",
    "    current, new = 1000000.0, 1000000.0\n",
    "    \n",
    "    while left and current == new:\n",
    "        \n",
    "        aics_cov = []\n",
    "        \n",
    "        for covariate in left:\n",
    "            columns = picked + [covariate]\n",
    "            loss = logistic_regression(y, x[:,columns], np.zeros(len(columns)), 100000, 0.01)[1]\n",
    "            aic = 2*loss + 2*len(columns)\n",
    "            aics_cov.append((aic, covariate))\n",
    "        \n",
    "        aics_cov.sort()\n",
    "        new, best_cov = aics_cov[0]\n",
    "        \n",
    "        if current > new:\n",
    "            left.remove(best_cov)\n",
    "            picked.append(best_cov)\n",
    "            current = new\n",
    "            \n",
    "    return np.array(x_pd.columns)[picked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train data\n",
    "#y, tx, ids = load_csv_data('Data/train.csv', sub_sample=True)\n",
    "#intercept = np.ones((tx.shape[0], 1))\n",
    "#tx = np.concatenate((intercept, tx), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit whole data\n",
    "#w1, loss1 = logistic_regression(y, tx, np.zeros(tx.shape[1]), 100000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train validation\n",
    "#preds = predict(tx,w1)\n",
    "#(preds == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Train Data**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load sub sample of train data\n",
    "x = pd.read_csv('Data/train.csv')\n",
    "x = x.iloc[::25, :]\n",
    "x['Intercept'] = 1\n",
    "x[\"Prediction\"] = x[\"Prediction\"].apply(lambda p: 1 if p=='s' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for jet value=0\n",
    "y_j0 = np.array(x[x[\"PRI_jet_num\"]==0].Prediction)\n",
    "\n",
    "df_j0 = x[x[\"PRI_jet_num\"]==0].drop(columns=['Prediction','DER_deltaeta_jet_jet', \n",
    "                                               'DER_mass_jet_jet', 'DER_prodeta_jet_jet', \n",
    "                                               'DER_lep_eta_centrality', 'PRI_jet_leading_pt',\n",
    "                                               'PRI_jet_leading_eta', 'PRI_jet_leading_phi', \n",
    "                                               'PRI_jet_subleading_pt','PRI_jet_subleading_eta', \n",
    "                                               'PRI_jet_subleading_phi','PRI_jet_num','Id','PRI_jet_all_pt'])\n",
    "\n",
    "mean_j0 = df_j0[df_j0['DER_mass_MMC'] != -999].DER_mass_MMC.mean()\n",
    "df_j0 = df_j0.replace({'DER_mass_MMC': {-999: mean_j0}})\n",
    "#df_j0 = (df_j0 - df_j0.mean()) / df_j0.std()\n",
    "df_j0['Intercept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for jet value=1\n",
    "y_j1 = np.array(x[x[\"PRI_jet_num\"]==1].Prediction)\n",
    "\n",
    "df_j1 = x[x[\"PRI_jet_num\"]==1].drop(columns=['PRI_jet_num','Prediction', 'Id', 'DER_deltaeta_jet_jet',\n",
    "                                               'DER_mass_jet_jet', 'DER_prodeta_jet_jet',\n",
    "                                               'DER_lep_eta_centrality', 'PRI_jet_subleading_pt',\n",
    "                                               'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi'])\n",
    "\n",
    "mean_j1 = df_j1[df_j1['DER_mass_MMC'] != -999].DER_mass_MMC.mean()\n",
    "df_j1=df_j1.replace({'DER_mass_MMC': {-999: mean_j1}})\n",
    "#df_j1 = (df_j1 - df_j1.mean()) / df_j1.std()\n",
    "df_j1['Intercept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for jet value=2,3\n",
    "y_j23 = np.array(x[x[\"PRI_jet_num\"].isin([2,3])].Prediction)\n",
    "\n",
    "df_j23 = x[x[\"PRI_jet_num\"].isin([2,3])].drop(columns=['Prediction','Id','PRI_jet_num'])\n",
    "\n",
    "mean_j23 = df_j23[df_j23['DER_mass_MMC'] != -999].DER_mass_MMC.mean()\n",
    "df_j23=df_j23.replace({'DER_mass_MMC': {-999: mean_j23}})\n",
    "#df_j23 = (df_j23 - df_j23.mean()) / df_j23.std()\n",
    "df_j23['Intercept'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performing forward selection for each subgroup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ij0 = AIC_forward(y_j0, df_j0)\n",
    "ij0 = np.array(['Intercept', 'DER_mass_transverse_met_lep', 'PRI_tau_pt',\n",
    "       'DER_deltar_tau_lep', 'DER_mass_vis', 'DER_sum_pt', 'PRI_met'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jet0_aic = df_j0.loc[:, ij0]\n",
    "\n",
    "x_jet0_aic = np.array(df_jet0_aic)\n",
    "\n",
    "w0, loss0 = logistic_regression(y_j0, x_jet0_aic, np.zeros(ij0.shape), 100000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7658536585365854"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#jet=0\n",
    "preds = predict(x_jet0_aic, w0)\n",
    "(preds == y_j0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ij1 = AIC_forward(y_j1, df_j1)\n",
    "ij1 = np.array(['Intercept', 'DER_mass_transverse_met_lep', 'PRI_tau_pt',\n",
    "       'DER_met_phi_centrality', 'PRI_met', 'DER_pt_h', 'DER_sum_pt',\n",
    "       'DER_mass_vis', 'DER_deltar_tau_lep', 'DER_pt_tot',\n",
    "       'PRI_met_sumet', 'PRI_jet_leading_phi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jet1_aic = df_j1.loc[:, ij1]\n",
    "\n",
    "x_jet1_aic = np.array(df_jet1_aic)\n",
    "\n",
    "w1, loss1 = logistic_regression(y_j1, x_jet1_aic, np.zeros(ij1.shape), 100000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.645872715816005"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#jet=1\n",
    "preds = predict(x_jet1_aic, w1)\n",
    "(preds == y_j1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ij23 = AIC_forward(y_j23, df_j23)\n",
    "ij23 = np.array(['Intercept', 'DER_deltaeta_jet_jet', 'DER_met_phi_centrality',\n",
    "       'PRI_tau_pt', 'PRI_met_sumet', 'DER_lep_eta_centrality',\n",
    "       'DER_mass_transverse_met_lep', 'DER_mass_jet_jet',\n",
    "       'DER_pt_ratio_lep_tau', 'DER_pt_h', 'DER_deltar_tau_lep',\n",
    "       'PRI_lep_pt', 'DER_mass_vis', 'PRI_jet_all_pt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jet23_aic = df_j23.loc[:, ij23]\n",
    "\n",
    "x_jet23_aic = np.array(df_jet23_aic)\n",
    "\n",
    "w23, loss23 = logistic_regression(y_j23, x_jet23_aic, np.zeros(ij23.shape), 100000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44626407369498466"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#jet=2,3\n",
    "preds = predict(x_jet23_aic, w23)\n",
    "(preds == y_j23).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Data Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = pd.read_csv('Data/test.csv')\n",
    "x_t['Intercept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for jet value=0\n",
    "\n",
    "ids_j0 = x_t[x_t[\"PRI_jet_num\"]==0].Id\n",
    "\n",
    "df_j0t = x_t[x_t[\"PRI_jet_num\"]==0].drop(columns=['Prediction','DER_deltaeta_jet_jet', \n",
    "                                               'DER_mass_jet_jet', 'DER_prodeta_jet_jet', \n",
    "                                               'DER_lep_eta_centrality', 'PRI_jet_leading_pt',\n",
    "                                               'PRI_jet_leading_eta', 'PRI_jet_leading_phi', \n",
    "                                               'PRI_jet_subleading_pt','PRI_jet_subleading_eta', \n",
    "                                               'PRI_jet_subleading_phi','PRI_jet_num','Id','PRI_jet_all_pt'])\n",
    "\n",
    "df_j0t=df_j0t.replace({'DER_mass_MMC': {-999: mean_j0}})\n",
    "#df_j0t = (df_j0t - df_j0.mean()) / df_j0.std()\n",
    "df_j0t['Intercept'] = 1\n",
    "df_j0t = df_j0t.loc[:, ij0]\n",
    "x_j0t = np.array(df_j0t)\n",
    "preds_j0t = predict(x_j0t, w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for jet value=1\n",
    "\n",
    "ids_j1 = x_t[x_t[\"PRI_jet_num\"]==1].Id\n",
    "\n",
    "df_j1t = x_t[x_t[\"PRI_jet_num\"]==1].drop(columns=['PRI_jet_num','Prediction', 'Id', 'DER_deltaeta_jet_jet',\n",
    "                                               'DER_mass_jet_jet', 'DER_prodeta_jet_jet',\n",
    "                                               'DER_lep_eta_centrality', 'PRI_jet_subleading_pt',\n",
    "                                               'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi'])\n",
    "\n",
    "df_j1t=df_j1t.replace({'DER_mass_MMC': {-999: mean_j1}})\n",
    "#df_j1t = (df_j1t - df_j1.mean()) / df_j1.std()\n",
    "df_j1t['Intercept'] = 1\n",
    "df_j1t = df_j1t.loc[:, ij1]\n",
    "x_j1t = np.array(df_j1t)\n",
    "preds_j1t = predict(x_j1t, w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for jet value=2,3\n",
    "\n",
    "ids_j23 = x_t[x_t[\"PRI_jet_num\"].isin([2,3])].Id\n",
    "\n",
    "df_j23t = x_t[x_t[\"PRI_jet_num\"].isin([2,3])].drop(columns=['Prediction','Id','PRI_jet_num'])\n",
    "\n",
    "df_j23t=df_j23t.replace({'DER_mass_MMC': {-999: mean_j23}})\n",
    "#df_j23t = (df_j23t - df_j23.mean()) / df_j23.std()\n",
    "df_j23t['Intercept'] = 1\n",
    "df_j23t = df_j23t.loc[:, ij23]\n",
    "x_j23t = np.array(df_j23t)\n",
    "preds_j23t = predict(x_j23t, w23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ids_j0.tolist() + ids_j1.tolist() + ids_j23.tolist()\n",
    "y_pred = preds_j0t.tolist() + preds_j1t.tolist() + preds_j23t.tolist()\n",
    "y_pred = [1 if pred else -1 for pred in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(ids, y_pred, 'pred1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
